{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Lab #2-3 (종합 과제): 로지스틱 회귀 vs. K-NN 모델 비교 및 ROC 커브 시각화 (정답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 기본 라이브러리 및 데이터 준비 (튜토리얼 본문 코드 재사용) ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "path = './WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
    "df = pd.read_csv(path)\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df.drop('customerID', axis=1, inplace=True)\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "numeric_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include='object').columns.tolist()\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features), ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [문제 1] 두 모델 학습 및 성능 평가 (정답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀 파이프라인 생성 및 학습\n",
    "lr_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', LogisticRegression(solver='liblinear', random_state=42))])\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# K-NN(k=11) 파이프라인 생성 및 학습\n",
    "knn_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', KNeighborsClassifier(n_neighbors=11))])\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 확률 계산 (ROC-AUC 계산용)\n",
    "y_pred_proba_lr = lr_pipeline.predict_proba(X_test)[:, 1]\n",
    "y_pred_proba_knn = knn_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 각 모델의 정확도와 ROC-AUC 점수 계산 및 출력\n",
    "acc_lr = accuracy_score(y_test, lr_pipeline.predict(X_test))\n",
    "auc_lr = roc_auc_score(y_test, y_pred_proba_lr)\n",
    "acc_knn = accuracy_score(y_test, knn_pipeline.predict(X_test))\n",
    "auc_knn = roc_auc_score(y_test, y_pred_proba_knn)\n",
    "\n",
    "print(f\"로지스틱 회귀 정확도: {acc_lr:.4f}, ROC-AUC: {auc_lr:.4f}\")\n",
    "print(f\"K-NN (k=11) 정확도: {acc_knn:.4f}, ROC-AUC: {auc_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [문제 2] ROC 커브 시각화 (정답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 모델의 ROC 커브 계산\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_proba_lr)\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y_test, y_pred_proba_knn)\n",
    "\n",
    "# Plotly를 사용하여 ROC 커브 시각화\n",
    "fig = go.Figure()\n",
    "\n",
    "# 로지스틱 회귀 ROC 커브 추가\n",
    "fig.add_trace(go.Scatter(x=fpr_lr, y=tpr_lr, mode='lines', name=f'Logistic Regression (AUC={auc_lr:.4f})'))\n",
    "\n",
    "# K-NN ROC 커브 추가\n",
    "fig.add_trace(go.Scatter(x=fpr_knn, y=tpr_knn, mode='lines', name=f'K-NN, k=11 (AUC={auc_knn:.4f})'))\n",
    "\n",
    "# 램덤 추측선 (y=x) 추가\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Random Guess', line=dict(dash='dash')))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='로지스틱 회귀 vs. K-NN ROC 커브',\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "    xaxis=dict(constrain='domain'),\n",
    "    width=700, height=600\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [문제 3] 결과 분석 (정답 예시)\n",
    "\n",
    "1. **정확도(Accuracy)** 측면에서는 **로지스틱 회귀** 모델(약 0.8034)이 K-NN 모델(약 0.7743)보다 더 우수한 성능을 보입니다.\n",
    "\n",
    "2. **ROC-AUC 점수**와 **ROC 커브**를 종합적으로 고려했을 때도 **로지스틱 회귀** 모델이 더 우수합니다. 로지스틱 회귀의 AUC 점수(약 0.8468)가 K-NN(약 0.8122)보다 높으며, 그래프에서도 로지스틱 회귀의 ROC 커브가 K-NN의 커브보다 더 **왼쪽 위 모서리**에 가깝게 그려집니다. 이는 로지스틱 회귀가 모든 임계값(threshold) 수준에서 전반적으로 '진짜 이탈 고객(True Positive)'을 '가짜 이탈 고객(False Positive)'보다 더 잘 구분해낸다는 것을 의미합니다. 따라서 이 데이터셋에서는 로지스틱 회귀가 이탈 고객을 예측하는 데 더 적합한 모델이라고 결론 내릴 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
