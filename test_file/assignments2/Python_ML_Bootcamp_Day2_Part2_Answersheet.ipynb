{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”‘ Part 2 ì—°ìŠµë¬¸ì œ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ì—°ìŠµë¬¸ì œ ì •ë‹µ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNFa-upj6We3"
      },
      "outputs": [],
      "source": [
        "# ì—°ìŠµë¬¸ì œ 1 ì •ë‹µ\n",
        "imputer_median = SimpleImputer(strategy='median')\n",
        "df_imputed_median = imputer_median.fit_transform(df_numeric)\n",
        "df_imputed_median = pd.DataFrame(df_imputed_median, columns=df_numeric.columns)\n",
        "# ì¤‘ì•™ê°’ìœ¼ë¡œ ì±„ì›Œì§„ í›„ ê²°ì¸¡ì¹˜ê°€ ì—†ëŠ”ì§€ í™•ì¸\n",
        "print(\"ì¤‘ì•™ê°’ ì²˜ë¦¬ í›„ ê²°ì¸¡ì¹˜ ê°œìˆ˜:\", df_imputed_median['TotalCharges'].isnull().sum()) # ì¶œë ¥: 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ì—°ìŠµë¬¸ì œ 2 ì •ë‹µ\n",
        "dependents_series = df['Dependents']\n",
        "le_dependents = LabelEncoder()\n",
        "dependents_encoded = le_dependents.fit_transform(dependents_series)\n",
        "print(\"ì›ë³¸ ë°ì´í„°:\", dependents_series.unique()) # ['No' 'Yes']\n",
        "print(\"ì¸ì½”ë”©ëœ ë°ì´í„°:\", np.unique(dependents_encoded)) # [0 1]\n",
        "print(\"ì¸ì½”ë”© í´ë˜ìŠ¤ í™•ì¸:\", le_dependents.classes_) # ['No' 'Yes']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ì—°ìŠµë¬¸ì œ 3 ì •ë‹µ\n",
        "payment_df = df[['PaymentMethod']]\n",
        "ohe_payment = OneHotEncoder(sparse_output=False)\n",
        "payment_onehot = ohe_payment.fit_transform(payment_df.fillna('Unknown'))\n",
        "print(\"ìƒì„±ëœ ë”ë¯¸ ë³€ìˆ˜ ê°œìˆ˜(shape):\", payment_onehot.shape) # (7043, 4)\n",
        "print(\"ìƒì„±ëœ ì»¬ëŸ¼ëª…:\", ohe_payment.get_feature_names_out())\n",
        "# ['PaymentMethod_Bank transfer (automatic)' 'PaymentMethod_Credit card (automatic)' 'PaymentMethod_Electronic check' 'PaymentMethod_Mailed check']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ì—°ìŠµë¬¸ì œ 4 ì •ë‹µ\n",
        "df_subset = df_imputed[['tenure', 'TotalCharges']]\n",
        "scaler_subset = StandardScaler()\n",
        "df_scaled_subset = scaler_subset.fit_transform(df_subset)\n",
        "print(df_scaled_subset[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ì—°ìŠµë¬¸ì œ 5 ì •ë‹µ\n",
        "print(pd.Series(y_train_resampled).value_counts(normalize=True))\n",
        "# 0    0.5\n",
        "# 1    0.5\n",
        "# Name: proportion, dtype: float64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì—°ìŠµë¬¸ì œ 6 ì •ë‹µ\n",
        "from lib.preperate import ImbalancedDataAnalyzer\n",
        "from lib.visualize import TSNEVisualizer\n",
        "from sklearn.utils import resample\n",
        "\n",
        "analyzer = ImbalancedDataAnalyzer(X_train, y_train)\n",
        "\n",
        "X_adasyn, y_adasyn = analyzer.adasyn()\n",
        "print(f\"ADASYN ìƒ˜í”Œë§ í›„ ë°ì´í„° í¬ê¸°: {X_adasyn.shape}\")\n",
        "print(f\"ADASYN í´ë˜ìŠ¤ ë¶„í¬:\\n{pd.Series(y_adasyn).value_counts()}\")\n",
        "\n",
        "X_smote_tomek, y_smote_tomek = analyzer.smote_tomek()\n",
        "print(f\"\\nSMOTE+Tomek ìƒ˜í”Œë§ í›„ ë°ì´í„° í¬ê¸°: {X_smote_tomek.shape}\")\n",
        "print(f\"SMOTE+Tomek í´ë˜ìŠ¤ ë¶„í¬:\\n{pd.Series(y_smote_tomek).value_counts()}\")\n",
        "\n",
        "X_smote_enn, y_smote_enn = analyzer.smote_enn()\n",
        "print(f\"\\nSMOTE+ENN ìƒ˜í”Œë§ í›„ ë°ì´í„° í¬ê¸°: {X_smote_enn.shape}\")\n",
        "print(f\"SMOTE+ENN í´ë˜ìŠ¤ ë¶„í¬:\\n{pd.Series(y_smote_enn).value_counts()}\")\n",
        "\n",
        "df_adasyn = pd.DataFrame(X_adasyn, columns=X_train.columns)\n",
        "df_adasyn['target'] = y_adasyn\n",
        "X_adasyn_sample, y_adasyn_sample = resample(df_adasyn.drop('target', axis=1), \n",
        "                                           df_adasyn['target'], \n",
        "                                           n_samples=3000, \n",
        "                                           random_state=42)\n",
        "\n",
        "df_smote_tomek = pd.DataFrame(X_smote_tomek, columns=X_train.columns)\n",
        "df_smote_tomek['target'] = y_smote_tomek\n",
        "X_smote_tomek_sample, y_smote_tomek_sample = resample(df_smote_tomek.drop('target', axis=1), \n",
        "                                                     df_smote_tomek['target'], \n",
        "                                                     n_samples=3000, \n",
        "                                                     random_state=42)\n",
        "\n",
        "df_smote_enn = pd.DataFrame(X_smote_enn, columns=X_train.columns)\n",
        "df_smote_enn['target'] = y_smote_enn\n",
        "X_smote_enn_sample, y_smote_enn_sample = resample(df_smote_enn.drop('target', axis=1), \n",
        "                                                 df_smote_enn['target'], \n",
        "                                                 n_samples=3000, \n",
        "                                                 random_state=42)\n",
        "\n",
        "print(f\"\\n3000ê°œ ìƒ˜í”Œë§ í›„:\")\n",
        "print(f\"ADASYN í´ë˜ìŠ¤ ë¶„í¬: {pd.Series(y_adasyn_sample).value_counts()}\")\n",
        "print(f\"SMOTE+Tomek í´ë˜ìŠ¤ ë¶„í¬: {pd.Series(y_smote_tomek_sample).value_counts()}\")\n",
        "print(f\"SMOTE+ENN í´ë˜ìŠ¤ ë¶„í¬: {pd.Series(y_smote_enn_sample).value_counts()}\")\n",
        "\n",
        "TSNEVisualizer.visualize(X_adasyn_sample, y_adasyn_sample, 'ADASYN t-SNE ì‹œê°í™”')\n",
        "TSNEVisualizer.visualize(X_smote_tomek_sample, y_smote_tomek_sample, 'SMOTE+Tomek t-SNE ì‹œê°í™”')\n",
        "TSNEVisualizer.visualize(X_smote_enn_sample, y_smote_enn_sample, 'SMOTE+ENN t-SNE ì‹œê°í™”')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ì—°ìŠµë¬¸ì œ 7 ì •ë‹µ\n",
        "numeric_transformer_minmax = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "preprocessor_minmax = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer_minmax, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "model_pipeline_minmax = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor_minmax),\n",
        "    ('classifier', LogisticRegression(solver='liblinear'))\n",
        "])\n",
        "model_pipeline_minmax.fit(X_train, y_train)\n",
        "accuracy_minmax = model_pipeline_minmax.score(X_test, y_test)\n",
        "print(f\"MinMaxScaler íŒŒì´í”„ë¼ì¸ ëª¨ë¸ì˜ ì •í™•ë„: {accuracy_minmax:.4f}\") # 0.8204"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì—°ìŠµë¬¸ì œ 8 ì •ë‹µ\n",
        "\n",
        "# íŠ¹ì„±(X)ê³¼ íƒ€ê²Ÿ(y) ë¶„ë¦¬\n",
        "X = df_heart.drop('DEATH_EVENT', axis=1)\n",
        "y = df_heart['DEATH_EVENT']\n",
        "\n",
        "# í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "# [ë¬¸ì œ 1] ìˆ˜ì¹˜í˜• íŠ¹ì„±ê³¼ ë²”ì£¼í˜•(ì´ì§„) íŠ¹ì„±ì˜ ì»¬ëŸ¼ëª…ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜í•˜ì„¸ìš”.\n",
        "numeric_features = ['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'time']\n",
        "categorical_features = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']\n",
        "\n",
        "# [ë¬¸ì œ 2] ColumnTransformerë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²˜ë¦¬ê¸°ë¥¼ ë§Œë“œì„¸ìš”.\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(), categorical_features)\n",
        "    ])\n",
        "\n",
        "# [ë¬¸ì œ 3] Pipelineì„ ì‚¬ìš©í•˜ì—¬ ì „ì²˜ë¦¬ê¸°ì™€ RandomForestClassifier ëª¨ë¸ì„ ì—°ê²°í•˜ì„¸ìš”.\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# [ë¬¸ì œ 4] ìƒì„±í•œ íŒŒì´í”„ë¼ì¸ì„ í›ˆë ¨ ë°ì´í„°ë¡œ í•™ìŠµì‹œí‚¤ì„¸ìš”.\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# [ë¬¸ì œ 5] í•™ìŠµëœ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ì •í™•ë„ë¥¼ ê³„ì‚°í•˜ì—¬ ì¶œë ¥í•˜ì„¸ìš”.\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"ì‹¬ë¶€ì „ ì˜ˆì¸¡ ëª¨ë¸ íŒŒì´í”„ë¼ì¸ì˜ ì •í™•ë„: {accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
