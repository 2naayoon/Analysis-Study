{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔑 Day 3-1 연습문제 정답지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 연습문제 1: 소프트 보팅에 가중치 적용\n",
        "voting_clf_weighted = VotingClassifier(\n",
        "    estimators=[('lr', lr_clf), ('knn', knn_clf), ('dt', dt_clf)],\n",
        "    voting='soft',\n",
        "    weights=[2, 2, 1]\n",
        ")\n",
        "\n",
        "voting_clf_weighted.fit(X_train, y_train)\n",
        "weighted_accuracy = voting_clf_weighted.score(X_test, y_test)\n",
        "print(f'Weighted Soft Voting Accuracy: {weighted_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 연습문제 2: BaggingClassifier의 estimator를 LogisticRegression으로 변경\n",
        "bagging_lr_clf = BaggingClassifier(\n",
        "    estimator=Pipeline([('preprocessor', preprocessor),\n",
        "                             ('classifier', LogisticRegression(random_state=42))]),\n",
        "    n_estimators=30,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "bagging_lr_clf.fit(X_train, y_train)\n",
        "lr_bagging_accuracy = bagging_lr_clf.score(X_test, y_test)\n",
        "print(f'Bagging (Logistic Regression) Accuracy: {lr_bagging_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 연습문제 3: AdaBoostClassifier의 learning_rate를 1.0으로 변경\n",
        "adaboost_clf_lr1 = AdaBoostClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=1, random_state=42),\n",
        "    n_estimators=50,\n",
        "    learning_rate=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "adaboost_clf_lr1.fit(X_train_processed, y_train)\n",
        "ada_lr1_accuracy = adaboost_clf_lr1.score(X_test_processed, y_test)\n",
        "print(f'AdaBoost (learning_rate=1.0) Accuracy: {ada_lr1_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 연습문제 4: 메타 모델이 DecisionTree인 StackingClassifier 정의\n",
        "stacking_dt_clf = StackingClassifier(\n",
        "    estimators=[('lr', lr_clf), ('knn', knn_clf), ('dt', dt_clf)],\n",
        "    final_estimator=DecisionTreeClassifier(random_state=42),\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "stacking_dt_clf.fit(X_train, y_train)\n",
        "stacking_dt_accuracy = stacking_dt_clf.score(X_test, y_test)\n",
        "print(f'Stacking (Meta=DT) Accuracy: {stacking_dt_accuracy:.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
