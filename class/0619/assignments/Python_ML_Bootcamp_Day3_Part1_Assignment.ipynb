{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVd-tMt-Tmbw"
      },
      "source": [
        "### 📝 Lab #3 (Part 1 응용): 최고의 앙상블 기법 찾기\n",
        "\n",
        "지금까지 배운 4가지 앙상블 기법(Voting, Bagging, Boosting, Stacking)을 모두 사용하여, 심부전 예측 문제에서 어떤 기법이 가장 높은 성능을 보이는지 비교 분석하는 미니 프로젝트를 수행합니다.\n",
        "\n",
        "#### 과제 목표\n",
        "\n",
        "1.  Voting, Bagging, AdaBoost, Stacking 분류기를 각각 생성하고 학습시킵니다.\n",
        "    * **Voting**: Soft Voting 방식을 사용합니다.\n",
        "    * **Bagging**: 결정 트리를 기본 모델로 사용하고, `n_estimators=100`으로 설정합니다.\n",
        "    * **AdaBoost**: `n_estimators=100`, `learning_rate=0.1`로 설정합니다.\n",
        "    * **Stacking**: 기본 모델은 `LogisticRegression`과 `KNeighborsClassifier`를 사용하고, 메타 모델은 `DecisionTreeClassifier`를 사용합니다.\n",
        "2.  각 모델의 **정확도(Accuracy)**와 **ROC-AUC 점수**를 계산하여 성능을 비교합니다.\n",
        "3.  `Plotly Express`를 사용하여 각 모델의 성능 지표를 **막대 그래프**로 시각화하고, 어떤 모델이 가장 우수한지 분석합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import VotingClassifier, BaggingClassifier, AdaBoostClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import plotly.express as px\n",
        "\n",
        "# 데이터 불러오기\n",
        "path = '../../datasets/ml/heart-failure/heart_failure_clinical_records_dataset.csv'\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "# 1. 특성과 타겟을 분리하세요.\n",
        "\n",
        "# 2. 학습 데이터와 테스트 데이터로 분할하세요. (test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# 3. Soft Voting 방식의 VotingClassifier를 생성하고 학습시키세요.\n",
        "#    (LogisticRegression, KNeighborsClassifier, DecisionTreeClassifier 사용)\n",
        "\n",
        "# 4. VotingClassifier의 예측값과 예측확률을 구하고, 정확도와 ROC-AUC 점수를 계산하세요.\n",
        "\n",
        "# 5. BaggingClassifier(기본모델: DecisionTree, n_estimators=100)를 생성하고 학습시키세요.\n",
        "\n",
        "# 6. BaggingClassifier의 예측값과 예측확률을 구하고, 정확도와 ROC-AUC 점수를 계산하세요.\n",
        "\n",
        "# 7. AdaBoostClassifier(n_estimators=100, learning_rate=0.1)를 생성하고 학습시키세요.\n",
        "\n",
        "# 8. AdaBoostClassifier의 예측값과 예측확률을 구하고, 정확도와 ROC-AUC 점수를 계산하세요.\n",
        "\n",
        "# 9. StackingClassifier(기본: LogisticRegression, KNN / 메타: DecisionTree, cv=5)를 생성하고 학습시키세요.\n",
        "\n",
        "# 10. StackingClassifier의 예측값과 예측확률을 구하고, 정확도와 ROC-AUC 점수를 계산하세요.\n",
        "\n",
        "# 11. 각 모델의 성능(정확도, ROC-AUC)을 데이터프레임으로 정리하세요.\n",
        "\n",
        "# 12. Plotly를 사용하여 각 모델의 정확도와 ROC-AUC를 막대그래프로 시각화하세요.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
