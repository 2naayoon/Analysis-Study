{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### ğŸ”‘ Part 4 ì—°ìŠµë¬¸ì œ ì •ë‹µ\n",
        "\n",
        "#### ì—°ìŠµë¬¸ì œ 1 ì •ë‹µ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_xc2eeCjSn4"
      },
      "outputs": [],
      "source": [
        "# 1. ìƒˆë¡œìš´ ê¸°ë³¸ ëª¨ë¸ ì¶”ê°€\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "base_estimators_new = [\n",
        "    ('random_forest', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
        "    ('xgboost', XGBRegressor(random_state=42)),\n",
        "    ('gb', GradientBoostingRegressor(n_estimators=50, random_state=42)) # Gradient Boosting ì¶”ê°€\n",
        "]\n",
        "\n",
        "# 2. ìƒˆë¡œìš´ ë©”íƒ€ ëª¨ë¸ ì •ì˜\n",
        "meta_estimator_new = Lasso(alpha=1.0, random_state=42)\n",
        "\n",
        "# ê° ê¸°ë³¸ ëª¨ë¸ì„ ìœ„í•œ íŒŒì´í”„ë¼ì¸ ì¬ìƒì„±\n",
        "rf_pipeline_new = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', base_estimators_new[0][1])])\n",
        "xgb_pipeline_new = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', base_estimators_new[1][1])])\n",
        "gb_pipeline_new = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', base_estimators_new[2][1])])\n",
        "\n",
        "stacking_estimators_new = [\n",
        "    ('random_forest', rf_pipeline_new),\n",
        "    ('xgboost', xgb_pipeline_new),\n",
        "    ('gb', gb_pipeline_new)\n",
        "]\n",
        "\n",
        "# 3. ìƒˆë¡œìš´ StackingRegressor ìƒì„± ë° í•™ìŠµ\n",
        "# ë©”íƒ€ ëª¨ë¸ì´ ì„ í˜• ëª¨ë¸ì´ë¯€ë¡œ ìŠ¤ì¼€ì¼ë§ì´ í•„ìš”. ê¸°ì¡´ preprocessorë¥¼ ì¬ì‚¬ìš©\n",
        "meta_pipeline_new = Pipeline(steps=[('scaler', StandardScaler()), ('lasso', meta_estimator_new)])\n",
        "\n",
        "stacking_regressor_new = StackingRegressor(\n",
        "    estimators=stacking_estimators_new,\n",
        "    final_estimator=meta_pipeline_new,\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "stacking_regressor_new.fit(X_train, y_train)\n",
        "\n",
        "# 4. ì„±ëŠ¥ í‰ê°€\n",
        "y_pred_stack_new = stacking_regressor_new.predict(X_test)\n",
        "rmse_stack_new = np.sqrt(mean_squared_error(y_test, y_pred_stack_new))\n",
        "print(f\"ìƒˆë¡œìš´ ìŠ¤íƒœí‚¹ ì•™ìƒë¸”(ë©”íƒ€ëª¨ë¸: Lasso)ì˜ RMSE: {rmse_stack_new:.4f}\")\n",
        "\n",
        "# ì´ì „ ê²°ê³¼ì™€ ë¹„êµ\n",
        "print(f\"ê¸°ì¡´ ìŠ¤íƒœí‚¹ ì•™ìƒë¸”(ë©”íƒ€ëª¨ë¸: Ridge)ì˜ RMSE: {rmse_stack:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KD9ORDljSn4"
      },
      "source": [
        "#### ì—°ìŠµë¬¸ì œ 2 ì •ë‹µ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vQd488rjSn4"
      },
      "outputs": [],
      "source": [
        "# 1. test_size=0.5ë¡œ ë°ì´í„° ë¶„í• \n",
        "X_train_a_half, X_valid_b_half, y_train_a_half, y_valid_b_half = train_test_split(\n",
        "    X_train, y_train, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"ê¸°ë³¸ ëª¨ë¸ í›ˆë ¨ ë°ì´í„° í¬ê¸° (50%): {X_train_a_half.shape[0]}\")\n",
        "print(f\"ë©”íƒ€ ëª¨ë¸ í›ˆë ¨ ë°ì´í„° í¬ê¸° (50%): {X_valid_b_half.shape[0]}\")\n",
        "\n",
        "# 2. ë™ì¼í•œ ê¸°ë³¸ ëª¨ë¸ë“¤ì„ train_a_halfë¡œ í•™ìŠµ\n",
        "trained_base_models_half = {}\n",
        "for name, model in base_models:\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                               ('regressor', model)])\n",
        "    pipeline.fit(X_train_a_half, y_train_a_half)\n",
        "    trained_base_models_half[name] = pipeline\n",
        "\n",
        "# 3. ë©”íƒ€ íŠ¹ì„± ìƒì„± ë° ë©”íƒ€ ëª¨ë¸ í•™ìŠµ\n",
        "meta_features_valid_half = pd.DataFrame()\n",
        "for name, model in trained_base_models_half.items():\n",
        "    meta_features_valid_half[name] = model.predict(X_valid_b_half)\n",
        "\n",
        "meta_model_blend_half = Ridge(random_state=42)\n",
        "meta_model_blend_half.fit(meta_features_valid_half, y_valid_b_half)\n",
        "\n",
        "# 4. ìµœì¢… ì˜ˆì¸¡ ë° ì„±ëŠ¥ í‰ê°€\n",
        "meta_features_test_half = pd.DataFrame()\n",
        "for name, model in trained_base_models_half.items():\n",
        "    meta_features_test_half[name] = model.predict(X_test)\n",
        "\n",
        "y_pred_blend_half = meta_model_blend_half.predict(meta_features_test_half)\n",
        "rmse_blend_half = np.sqrt(mean_squared_error(y_test, y_pred_blend_half))\n",
        "\n",
        "print(f\"\\në¸”ë Œë”© ì•™ìƒë¸”(test_size=0.5)ì˜ RMSE: {rmse_blend_half:.4f}\")\n",
        "print(f\"ê¸°ì¡´ ë¸”ë Œë”© ì•™ìƒë¸”(test_size=0.3)ì˜ RMSE: {rmse_blend:.4f}\")\n",
        "\n",
        "# ê²°ê³¼ ë¶„ì„:\n",
        "# test_sizeë¥¼ 0.3ì—ì„œ 0.5ë¡œ ëŠ˜ë¦¬ë©´ ê¸°ë³¸ ëª¨ë¸ì´ í•™ìŠµí•  ë°ì´í„°(train_a)ëŠ” ì¤„ì–´ë“¤ê³ ,\n",
        "# ë©”íƒ€ ëª¨ë¸ì´ í•™ìŠµí•  ë°ì´í„°(valid_b)ëŠ” ëŠ˜ì–´ë‚©ë‹ˆë‹¤.\n",
        "# ê¸°ë³¸ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ì•½ê°„ ì €í•˜ë  ìˆ˜ ìˆì§€ë§Œ, ë©”íƒ€ ëª¨ë¸ì€ ë” ë§ì€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•˜ë¯€ë¡œ\n",
        "# ë” ì•ˆì •ì ì¸ ì¡°í•© ê°€ì¤‘ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìµœì¢… ì„±ëŠ¥ì€ ì´ ë‘ íš¨ê³¼ì˜ ìƒì¶© ê´€ê³„ì— ë”°ë¼ ê²°ì •ë©ë‹ˆë‹¤.\n",
        "# ë°ì´í„°ì…‹ì´ ì‘ì„ìˆ˜ë¡ train_aì˜ í¬ê¸°ë¥¼ ì¤„ì´ëŠ” ê²ƒì´ ì„±ëŠ¥ì— ë” í° ì•…ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
