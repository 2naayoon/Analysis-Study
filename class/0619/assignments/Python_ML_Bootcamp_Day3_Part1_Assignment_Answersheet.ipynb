{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVd-tMt-Tmbw"
      },
      "source": [
        "### 📝 Lab #3 (Part 1 응용): 최고의 앙상블 기법 찾기\n",
        "\n",
        "지금까지 배운 4가지 앙상블 기법(Voting, Bagging, Boosting, Stacking)을 모두 사용하여, 심부전 예측 문제에서 어떤 기법이 가장 높은 성능을 보이는지 비교 분석하는 미니 프로젝트를 수행합니다.\n",
        "\n",
        "#### 과제 목표\n",
        "\n",
        "1.  Voting, Bagging, AdaBoost, Stacking 분류기를 각각 생성하고 학습시킵니다.\n",
        "    * **Voting**: Soft Voting 방식을 사용합니다.\n",
        "    * **Bagging**: 결정 트리를 기본 모델로 사용하고, `n_estimators=100`으로 설정합니다.\n",
        "    * **AdaBoost**: `n_estimators=100`, `learning_rate=0.1`로 설정합니다.\n",
        "    * **Stacking**: 기본 모델은 `LogisticRegression`과 `KNeighborsClassifier`를 사용하고, 메타 모델은 `DecisionTreeClassifier`를 사용합니다.\n",
        "2.  각 모델의 **정확도(Accuracy)**와 **ROC-AUC 점수**를 계산하여 성능을 비교합니다.\n",
        "3.  `Plotly Express`를 사용하여 각 모델의 성능 지표를 **막대 그래프**로 시각화하고, 어떤 모델이 가장 우수한지 분석합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import VotingClassifier, BaggingClassifier, AdaBoostClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import plotly.express as px\n",
        "\n",
        "# 데이터 불러오기\n",
        "path = '../../datasets/ml/heart-failure/heart_failure_clinical_records_dataset.csv'\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "# 특성과 타겟 분리\n",
        "X = df.drop('DEATH_EVENT', axis=1)\n",
        "y = df['DEATH_EVENT']\n",
        "\n",
        "# 학습/테스트 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 1. Voting Classifier (Soft Voting)\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', LogisticRegression(max_iter=1000, random_state=42)),\n",
        "        ('knn', KNeighborsClassifier()),\n",
        "        ('dt', DecisionTreeClassifier(random_state=42))\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "voting_clf.fit(X_train, y_train)\n",
        "y_pred_voting = voting_clf.predict(X_test)\n",
        "y_proba_voting = voting_clf.predict_proba(X_test)[:,1]\n",
        "acc_voting = accuracy_score(y_test, y_pred_voting)\n",
        "roc_voting = roc_auc_score(y_test, y_proba_voting)\n",
        "\n",
        "# 2. Bagging Classifier (DecisionTree, n_estimators=100)\n",
        "bagging_clf = BaggingClassifier(\n",
        "    base_estimator=DecisionTreeClassifier(random_state=42),\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging_clf.predict(X_test)\n",
        "y_proba_bagging = bagging_clf.predict_proba(X_test)[:,1]\n",
        "acc_bagging = accuracy_score(y_test, y_pred_bagging)\n",
        "roc_bagging = roc_auc_score(y_test, y_proba_bagging)\n",
        "\n",
        "# 3. AdaBoost Classifier (n_estimators=100, learning_rate=0.1)\n",
        "adaboost_clf = AdaBoostClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "adaboost_clf.fit(X_train, y_train)\n",
        "y_pred_adaboost = adaboost_clf.predict(X_test)\n",
        "y_proba_adaboost = adaboost_clf.predict_proba(X_test)[:,1]\n",
        "acc_adaboost = accuracy_score(y_test, y_pred_adaboost)\n",
        "roc_adaboost = roc_auc_score(y_test, y_proba_adaboost)\n",
        "\n",
        "# 4. Stacking Classifier (base: LogisticRegression, KNN / meta: DecisionTree)\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', LogisticRegression(max_iter=1000, random_state=42)),\n",
        "        ('knn', KNeighborsClassifier())\n",
        "    ],\n",
        "    final_estimator=DecisionTreeClassifier(random_state=42),\n",
        "    passthrough=False,\n",
        "    cv=5\n",
        ")\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "y_pred_stacking = stacking_clf.predict(X_test)\n",
        "y_proba_stacking = stacking_clf.predict_proba(X_test)[:,1]\n",
        "acc_stacking = accuracy_score(y_test, y_pred_stacking)\n",
        "roc_stacking = roc_auc_score(y_test, y_proba_stacking)\n",
        "\n",
        "# 결과 정리\n",
        "results = pd.DataFrame({\n",
        "    'Model': ['Voting', 'Bagging', 'AdaBoost', 'Stacking'],\n",
        "    'Accuracy': [acc_voting, acc_bagging, acc_adaboost, acc_stacking],\n",
        "    'ROC-AUC': [roc_voting, roc_bagging, roc_adaboost, roc_stacking]\n",
        "})\n",
        "\n",
        "# Plotly로 시각화\n",
        "fig_acc = px.bar(results, x='Model', y='Accuracy', title='앙상블 모델별 정확도(Accuracy)', text='Accuracy', color='Model')\n",
        "fig_roc = px.bar(results, x='Model', y='ROC-AUC', title='앙상블 모델별 ROC-AUC', text='ROC-AUC', color='Model')\n",
        "\n",
        "fig_acc.show()\n",
        "fig_roc.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
