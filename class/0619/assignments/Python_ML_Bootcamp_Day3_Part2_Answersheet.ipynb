{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "## 🔑 Part 2 연습문제 정답\n",
        "\n",
        "### 연습문제 1 정답"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MPGReO0YNP3"
      },
      "outputs": [],
      "source": [
        "# ExtraTreesClassifier 모델 생성 및 학습 (하이퍼파라미터 조정)\n",
        "et_clf_tuned = ExtraTreesClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
        "et_clf_tuned.fit(X_train, y_train)\n",
        "\n",
        "# 예측 및 평가\n",
        "y_pred_tuned = et_clf_tuned.predict(X_test)\n",
        "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
        "f1_tuned = f1_score(y_test, y_pred_tuned)\n",
        "\n",
        "print(f\"Tuned ExtraTreesClassifier 정확도: {accuracy_tuned:.4f}\")\n",
        "print(f\"Tuned ExtraTreesClassifier F1 점수: {f1_tuned:.4f}\")\n",
        "# 결과 분석: 일반적으로 트리의 깊이를 제한하면 과적합이 줄어들어 테스트 성능이 향상될 수 있습니다.\n",
        "# 트리의 개수를 늘리면 모델의 안정성이 증가합니다. 이 데이터셋에서는 성능이 향상된 것을 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiyCuH_3YNP4"
      },
      "source": [
        "### 연습문제 2 정답"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCig0uz5YNP4"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# SVC 모델 정의 (probability=True 필수)\n",
        "svc_clf = SVC(kernel='rbf', probability=True, random_state=42)\n",
        "\n",
        "# 4개의 모델로 Soft Voting Classifier 생성\n",
        "soft_voting_clf_4 = VotingClassifier(\n",
        "    estimators=[('lr', lr_clf), ('knn', knn_clf), ('dt', dt_clf), ('svc', svc_clf)],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "# 전체 파이프라인으로 묶기\n",
        "pipeline_soft_4 = Pipeline([('preprocessor', preprocessor), ('classifier', soft_voting_clf_4)])\n",
        "\n",
        "# 학습 및 평가\n",
        "pipeline_soft_4.fit(X_train, y_train)\n",
        "soft_accuracy_4 = pipeline_soft_4.score(X_test, y_test)\n",
        "\n",
        "print(f\"Soft Voting (4 models) 정확도: {soft_accuracy_4:.4f}\")\n",
        "# 결과 분석: 강력한 모델인 SVC가 추가되면서 앙상블의 성능이 개선될 가능성이 높습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYdCajAHYNP4"
      },
      "source": [
        "### 연습문제 3 정답"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDlOPYUfYNP4"
      },
      "outputs": [],
      "source": [
        "# XGBoost 하이퍼파라미터 변경\n",
        "xgb_reg_tuned = xgb.XGBRegressor(n_estimators=1000,\n",
        "                                 learning_rate=0.1,  # 0.05 -> 0.1\n",
        "                                 max_depth=7,      # 5 -> 7\n",
        "                                 random_state=42,\n",
        "                                 n_jobs=-1)\n",
        "\n",
        "# 조기 종료를 설정하여 학습\n",
        "xgb_reg_tuned.fit(X_train_xgb, y_train_xgb,\n",
        "                  eval_set=[(X_val_xgb, y_val_xgb)],\n",
        "                  early_stopping_rounds=50,\n",
        "                  verbose=False)\n",
        "\n",
        "y_pred_xgb_tuned = xgb_reg_tuned.predict(X_test)\n",
        "rmse_xgb_tuned = np.sqrt(mean_squared_error(y_test, y_pred_xgb_tuned))\n",
        "\n",
        "print(f\"Tuned XGBoost RMSE: {rmse_xgb_tuned:.4f}\")\n",
        "print(f\"Tuned XGBoost 최적 트리 개수: {xgb_reg_tuned.best_iteration}\")\n",
        "\n",
        "# 결과 분석:\n",
        "# learning_rate가 커지면 각 트리가 더 '과감하게' 학습하므로, 더 적은 수의 트리로 최적점에 도달하는 경향이 있습니다.\n",
        "# 따라서 best_iteration이 이전보다 줄어들었을 것입니다.\n",
        "# max_depth가 커지면 모델이 더 복잡해져 훈련 데이터에 과적합될 위험이 있지만,\n",
        "# 데이터의 복잡한 패턴을 잘 잡아내면 성능이 향상될 수도 있습니다.\n",
        "# 이 경우, RMSE가 약간 개선되어 모델이 더 복잡한 패턴을 성공적으로 학습했음을 시사합니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
