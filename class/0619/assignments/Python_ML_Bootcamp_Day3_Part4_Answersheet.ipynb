{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaJjTafZx_On"
      },
      "source": [
        "### 🔑 Day3-4 연습문제 정답지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### 연습문제 1 정답"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D0NI7Jqx_On"
      },
      "outputs": [],
      "source": [
        "# 1. 훈련 데이터에 대한 Permutation Importance 계산\n",
        "result_train = permutation_importance(\n",
        "    model, X_train, y_train, n_repeats=10, random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "# 2. 결과 DataFrame 생성\n",
        "importances_train = pd.DataFrame(\n",
        "    {'feature': feature_names,\n",
        "     'importance_mean': result_train.importances_mean,\n",
        "     'importance_std': result_train.importances_std}\n",
        ").sort_values('importance_mean', ascending=False)\n",
        "\n",
        "\n",
        "# 3. 가장 중요한 특성 3가지 출력\n",
        "print(\"--- 훈련 데이터 기준 상위 3개 특성 중요도 ---\")\n",
        "print(importances_train.head(3))\n",
        "# 훈련 데이터에 대한 중요도는 모델이 학습 과정에서 얼마나 해당 특성에 의존했는지를 보여줍니다.\n",
        "# 과적합(overfitting)이 있다면, 테스트 데이터에서의 중요도와 순위가 달라질 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wz93OKMx_On"
      },
      "source": [
        "#### 연습문제 2 정답"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwRrj3F5x_On"
      },
      "outputs": [],
      "source": [
        "# 1. 'Benign(양성)'으로 올바르게 예측된 샘플 인덱스 찾기\n",
        "# 모델 예측과 실제값이 모두 0(Benign)인 경우\n",
        "preds_test = model.predict(X_test)\n",
        "correct_benign_indices = np.where((preds_test == 0) & (y_test == 0))[0]\n",
        "\n",
        "if len(correct_benign_indices) > 0:\n",
        "    target_index = correct_benign_indices[0] # 첫 번째 샘플 선택\n",
        "    print(f\"'Benign'으로 올바르게 예측된 샘플 인덱스: {target_index}\")\n",
        "\n",
        "    # 2. 해당 인덱스의 데이터로 LIME 설명 생성\n",
        "    instance_to_explain_benign = X_test.iloc[target_index]\n",
        "    explanation_benign = explainer.explain_instance(\n",
        "        instance_to_explain_benign,\n",
        "        model.predict_proba,\n",
        "        num_features=5\n",
        "    )\n",
        "\n",
        "    # 3. 결과 시각화\n",
        "    explanation_benign.show_in_notebook(show_table=True)\n",
        "else:\n",
        "    print(\"'Benign'으로 올바르게 예측된 샘플을 찾지 못했습니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UqwvI9Qx_On"
      },
      "source": [
        "#### 연습문제 3 정답"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFY2BF84x_On"
      },
      "outputs": [],
      "source": [
        "# summary_plot에서 가장 중요했던 'worst concave points' 특성에 대한 dependence_plot\n",
        "shap.dependence_plot(\"worst concave points\", shap_values[1], X_test,\n",
        "                     interaction_index=\"worst radius\") # 상호작용을 볼 다른 특성 지정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24Kptaaqx_On"
      },
      "source": [
        "**`dependence_plot` 해석:**\n",
        "\n",
        "  * X축은 선택한 특성(`worst concave points`)의 값, Y축은 해당 특성의 SHAP 값입니다.\n",
        "  * 점의 색은 `interaction_index`로 지정한 다른 특성(`worst radius`)의 값 크기를 나타냅니다.\n",
        "  * 이를 통해 `worst concave points` 값이 커질수록 SHAP 값이 어떻게 변하는지, 그리고 그 경향이 `worst radius` 값에 따라 어떻게 달라지는지(상호작용) 파악할 수 있습니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
