{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab #1 (Part 4): 서울시 따릉이 수요 예측 GBMs 모델 성능 비교\n",
        "\n",
        "지금까지 배운 Gradient Boosting 모델 3대장(XGBoost, LightGBM, CatBoost)을 모두 사용하여 '서울 따릉이' 수요 예측 문제를 해결해보고, 최종 성능을 비교 분석하여 최적의 모델을 찾아봅시다.\n",
        "\n",
        "### 과제 목표\n",
        "\n",
        "1.  간단한 특성 공학(Feature Engineering)을 수행합니다.\n",
        "2.  XGBoost, LightGBM, CatBoost 모델을 각각 학습시키고 성능(RMSE, R²)을 평가합니다.\n",
        "3.  세 모델의 성능을 시각적으로 비교하고 결과를 해석합니다.\n",
        "\n",
        "### Step 1: 데이터 준비 및 특성 공학\n",
        "\n",
        "기존에 사용한 `df_orig` 데이터프레임에 새로운 시간 관련 특성을 추가해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "\n",
        "\n",
        "df_final = pd.read_csv('./datasets/SeoulBikeData.csv', encoding='cp949')\n",
        "\n",
        "df_final.columns = ['Date', 'Rented_Bike_Count', 'Hour', 'Temperature', 'Humidity',\n",
        "                    'Wind_Speed', 'Visibility', 'Dew_Point_Temp', 'Solar_Radiation',\n",
        "                    'Rainfall', 'Snowfall', 'Seasons', 'Holiday', 'Functioning_Day']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 원본 데이터 로드\n",
        "df_final = pd.read_csv('../datasets/ml/bike-sharing/SeoulBikeData.csv', encoding='cp949')\n",
        "\n",
        "# 컬럼명 정리\n",
        "df_final.columns = ['Date', 'Rented_Bike_Count', 'Hour', 'Temperature', 'Humidity',\n",
        "                    'Wind_Speed', 'Visibility', 'Dew_Point_Temp', 'Solar_Radiation',\n",
        "                    'Rainfall', 'Snowfall', 'Seasons', 'Holiday', 'Functioning_Day']\n",
        "\n",
        "# 📌 특성 공학: 주중/주말, 출퇴근 시간 특성 추가\n",
        "df_final['Date'] = pd.to_datetime(df_final['Date'], format='%d/%m/%Y')\n",
        "df_final['Weekday'] = df_final['Date'].dt.weekday # 0:월, 6:일\n",
        "df_final['Is_Weekend'] = df_final['Weekday'].apply(lambda x: 1 if x >= 5 else 0)\n",
        "df_final['Is_Rush_Hour'] = df_final['Hour'].apply(lambda x: 1 if (x >= 7 and x <= 9) or (x >= 17 and x <= 19) else 0)\n",
        "\n",
        "# 사용할 특성 정의\n",
        "features = ['Hour', 'Temperature', 'Humidity', 'Wind_Speed', 'Visibility',\n",
        "            'Solar_Radiation', 'Rainfall', 'Snowfall', 'Seasons', 'Holiday',\n",
        "            'Functioning_Day', 'Is_Weekend', 'Is_Rush_Hour']\n",
        "target = 'Rented_Bike_Count'\n",
        "\n",
        "# 범주형 특성 목록\n",
        "categorical_features_final = ['Seasons', 'Holiday', 'Functioning_Day']\n",
        "\n",
        "X_final = df_final[features]\n",
        "y_final = df_final[target]\n",
        "\n",
        "# 학습/테스트 데이터 분리\n",
        "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(X_final, y_final, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: 3개 모델 학습 및 평가\n",
        "\n",
        "아래 가이드에 따라 XGBoost, LightGBM, CatBoost 모델을 각각 학습시키고, 결과를 `results` 리스트에 저장하세요.\n",
        "\n",
        "  * **XGBoost**: `pd.get_dummies`로 범주형 변수를 원-핫 인코딩한 데이터를 사용해야 합니다.\n",
        "  * **LightGBM**: `pd.get_dummies`로 인코딩된 데이터를 사용하거나, `pandas.Categorical` 타입으로 변환하여 직접 처리할 수 있습니다. 여기서는 XGBoost와 동일하게 인코딩된 데이터를 사용하겠습니다.\n",
        "  * **CatBoost**: 원-핫 인코딩되지 않은 원본 형태의 데이터를 사용하고, `cat_features` 인자를 꼭 설정해주세요.\n",
        "\n",
        "<!-- end list -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 결과 저장을 위한 리스트\n",
        "results = []\n",
        "\n",
        "# --- 1. XGBoost ---\n",
        "# XGBoost를 위한 데이터 전처리 (원-핫 인코딩)\n",
        "X_train_xgb_f = pd.get_dummies(X_train_f, columns=categorical_features_final, drop_first=True)\n",
        "X_test_xgb_f = pd.get_dummies(X_test_f, columns=categorical_features_final, drop_first=True)\n",
        "\n",
        "# 모델 학습\n",
        "xgb_final = xgb.XGBRegressor(random_state=42, n_jobs=-1)\n",
        "xgb_final.fit(X_train_xgb_f, y_train_f)\n",
        "y_pred_xgb_f = xgb_final.predict(X_test_xgb_f)\n",
        "\n",
        "# 성능 계산 및 저장\n",
        "rmse_xgb_f = np.sqrt(mean_squared_error(y_test_f, y_pred_xgb_f))\n",
        "r2_xgb_f = r2_score(y_test_f, y_pred_xgb_f)\n",
        "results.append({'Model': 'XGBoost', 'RMSE': rmse_xgb_f, 'R2': r2_xgb_f})\n",
        "\n",
        "\n",
        "# --- 2. LightGBM ---\n",
        "# LightGBM은 XGBoost와 동일한 데이터 사용\n",
        "lgbm_final = lgb.LGBMRegressor(random_state=42, n_jobs=-1)\n",
        "lgbm_final.fit(X_train_xgb_f, y_train_f) # XGBoost용으로 인코딩된 데이터 사용\n",
        "y_pred_lgbm_f = lgbm_final.predict(X_test_xgb_f)\n",
        "\n",
        "# 성능 계산 및 저장\n",
        "rmse_lgbm_f = np.sqrt(mean_squared_error(y_test_f, y_pred_lgbm_f))\n",
        "r2_lgbm_f = r2_score(y_test_f, y_pred_lgbm_f)\n",
        "results.append({'Model': 'LightGBM', 'RMSE': rmse_lgbm_f, 'R2': r2_lgbm_f})\n",
        "\n",
        "\n",
        "# --- 3. CatBoost ---\n",
        "# CatBoost는 원본 데이터 사용\n",
        "cat_final = cb.CatBoostRegressor(random_state=42, cat_features=categorical_features_final, verbose=0)\n",
        "cat_final.fit(X_train_f, y_train_f) # 인코딩 전 데이터 사용\n",
        "y_pred_cat_f = cat_final.predict(X_test_f)\n",
        "\n",
        "# 성능 계산 및 저장\n",
        "rmse_cat_f = np.sqrt(mean_squared_error(y_test_f, y_pred_cat_f))\n",
        "r2_cat_f = r2_score(y_test_f, y_pred_cat_f)\n",
        "results.append({'Model': 'CatBoost', 'RMSE': rmse_cat_f, 'R2': r2_cat_f})\n",
        "\n",
        "# 결과 데이터프레임 생성\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: 결과 비교 및 시각화\n",
        "\n",
        "`plotly.express`를 사용하여 세 모델의 RMSE와 R² 점수를 막대그래프로 비교해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RMSE 비교 시각화\n",
        "fig_rmse = px.bar(results_df.sort_values('RMSE'),\n",
        "                  x='Model',\n",
        "                  y='RMSE',\n",
        "                  title='Model Comparison: RMSE (Lower is Better)',\n",
        "                  color='Model',\n",
        "                  text_auto='.4f')\n",
        "fig_rmse.show()\n",
        "\n",
        "# R² Score 비교 시각화\n",
        "fig_r2 = px.bar(results_df.sort_values('R2', ascending=False),\n",
        "                x='Model',\n",
        "                y='R2',\n",
        "                title='Model Comparison: R² Score (Higher is Better)',\n",
        "                color='Model',\n",
        "                text_auto='.4f')\n",
        "fig_r2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: 결과 해석 (자율 양식)\n",
        "\n",
        "  * 어떤 모델이 가장 좋은 성능(가장 낮은 RMSE, 가장 높은 R²)을 보였나요?\n",
        "  * 각 모델의 학습 시간은 어땠나요? (코드를 수정하여 측정해보세요.)\n",
        "  * 이 데이터셋의 특성(범주형 변수의 존재, 데이터 크기 등)을 고려할 때, 왜 특정 모델이 더 좋은 성능을 보였을지 자신의 생각을 정리해보세요.\n",
        "  * 기타 생각해볼 점이 있다면 적어보세요."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
