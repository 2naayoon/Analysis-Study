## $ p(x|C) $는 어떻게 계산하나?

나이브베이즈 분류기에서 $ P(x|C) $는 "특정 클래스 $ C $에서 입력 데이터 $ x $가 관측될 조건부 확률"입니다. 이 확률은 **특성(피처)들이 서로 독립**이라는 가정 하에 계산이 단순화됩니다.

---

**1. 조건부 독립 가정에 따른 계산**

입력 데이터 $ x $가 여러 특성 $(x_1, x_2, ..., x_n)$으로 이루어져 있다면,  
나이브베이즈는 다음과 같이 계산합니다.

$$
P(x|C) = P(x_1, x_2, ..., x_n|C) = P(x_1|C) \times P(x_2|C) \times \cdots \times P(x_n|C)
$$

즉, 각 특성별 조건부 확률을 곱해서 전체 조건부 확률을 구합니다.

---

**2. 특성별 조건부 확률 $ P(x_i|C) $ 계산 방법**

- **이산형(범주형) 특성:**  
  각 특성값이 클래스 $ C $에서 등장한 횟수를 전체 클래스 $ C $의 샘플 수로 나눕니다.  
  예시:  
  $$
  P(\text{특성값}|\text{클래스}) = \frac{\text{클래스에서 해당 특성값 등장 횟수} + 1}{\text{클래스 내 전체 샘플 수} + \text{특성값의 종류 수}}
  $$
  여기서 +1은 라플라스 스무딩(Laplace smoothing)으로, 데이터에 없는 값의 확률이 0이 되는 것을 방지합니다.

- **연속형(실수형) 특성:**  
  보통 정규분포(Gaussian Naive Bayes)를 가정하여, 클래스 $ C $에서 해당 특성의 평균과 분산을 구해 확률밀도함수로 계산합니다.

---

**3. 실제 예시 (이산형 특성)**

예를 들어, 이메일이 스팸(Spam)인지 아닌지 분류할 때 "Free"라는 단어가 등장할 확률을 계산할 수 있습니다.

$$
P(\text{"Free"}|\text{Spam}) = \frac{\text{스팸 메일 중 "Free" 등장 횟수} + 1}{\text{스팸 메일 전체 단어 수} + \text{전체 단어 종류 수}}
$$

이렇게 각 단어(특성)별로 확률을 구한 뒤, 메시지에 포함된 단어들의 조건부 확률을 모두 곱해 전체 $ P(x|C) $를 구합니다.

---

**4. 실제 예시 (연속형 특성)**

1. 예시 데이터: 이진 분류 (y=0, y=1)와 연속형 특성

    연속형 특성(예: 키, 몸무게 등)을 가진 데이터에서, 각 클래스별로 특성값이 정규분포를 따른다고 가정합니다. 예를 들어, 두 개의 특성 $x_1, x_2$와 두 개의 클래스(y=0, y=1)가 있다고 합시다. 각 클래스별로 특성의 평균과 분산을 구해 정규분포로 모델링합니다.

    | 클래스 | $x_1$ 평균 | $x_1$ 분산 | $x_2$ 평균 | $x_2$ 분산 |
    |--------|-------------|-------------|-------------|-------------|
    | y=0    | -1.96       | 1.02        | -2.01       | 2.31        |
    | y=1    | 2.19        | 1.25        | 2.13        | 1.94        |

2. 새로운 데이터의 분류 과정

    예를 들어, 새로운 입력 $x_{\text{new}} = (0, 0)$이 주어졌을 때, 각 클래스에 속할 조건부 확률 $P(x_{\text{new}}|y)$을 계산합니다.  
    각 특성별로 정규분포 확률밀도함수를 사용해 계산하고, 두 특성의 값을 곱합니다.

    - $P(x_{\text{new}}|y=0) = \mathcal{N}(0; -1.96, 1.02) \times \mathcal{N}(0; -2.01, 2.31)$
    - $P(x_{\text{new}}|y=1) = \mathcal{N}(0; 2.19, 1.25) \times \mathcal{N}(0; 2.13, 1.94)$

    계산 결과 예시:
    - $P(x_{\text{new}}|y=0) \approx 0.0066$
    - $P(x_{\text{new}}|y=1) \approx 0.0047$

    여기에 각 클래스의 사전확률(예: y=0은 0.4, y=1은 0.6)을 곱해 사후확률을 구합니다.

    - $P(y=0|x_{\text{new}}) \propto 0.0066 \times 0.4 = 0.0026$
    - $P(y=1|x_{\text{new}}) \propto 0.0047 \times 0.6 = 0.0028$

    정규화하면,
    - $P(y=0|x_{\text{new}}) = 0.48$
    - $P(y=1|x_{\text{new}}) = 0.52$

    따라서 $x_{\text{new}}$는 y=1에 속할 확률이 더 높으므로, y=1로 분류됩니다.

---

**정리**

- $ P(x|C) $는 **특성별 조건부 확률의 곱** 으로 계산합니다.
- 특성별 조건부 확률은 **클래스별 빈도** (이산형) 또는 **정규분포의 확률밀도** (연속형)로 구합니다.
- 라플라스 스무딩 등으로 0 확률 문제를 방지합니다.

이렇게 계산된 $ P(x|C) $는 사전확률 $ P(C) $와 곱해져 최종적으로 사후확률 $ P(C|x) $ 계산에 사용됩니다.