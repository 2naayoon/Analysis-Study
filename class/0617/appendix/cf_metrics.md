# 분류 모델 평가 지표 쉽게 정리

분류 모델의 성능을 평가할 때 자주 사용하는 지표들을 쉽고 자세하게 정리합니다. 각각의 개념, 계산 방법, 해석, 그리고 실제로 어떤 상황에서 중요한지 예시와 함께 설명합니다.

---

## 1. 혼동 행렬(Confusion Matrix)

- **정의**: 분류 모델의 예측 결과와 실제 값의 관계를 표로 정리한 것.
- **구성**:
    - **TP (True Positive)**: 실제 Positive, 예측도 Positive
    - **TN (True Negative)**: 실제 Negative, 예측도 Negative
    - **FP (False Positive)**: 실제 Negative, 예측은 Positive (오탐)
    - **FN (False Negative)**: 실제 Positive, 예측은 Negative (미탐)

  |                | 실제 Positive | 실제 Negative |
  |----------------|--------------|--------------|
  | 예측 Positive  | TP           | FP           |
  | 예측 Negative  | FN           | TN           |

- **활용**: 모든 평가 지표의 기본이 되는 표입니다.

---

## 2. 정확도(Accuracy)

- **정의**: 전체 데이터 중에서 예측이 맞은 비율.
- **공식**:  
  $$
  \text{정확도} = \frac{TP + TN}{TP + TN + FP + FN}
  $$
- **해석**: 직관적으로 모델의 전체 예측 성능을 나타냅니다.
- **주의**: 데이터가 불균형(한 쪽 클래스가 많음)할 때는 신뢰하기 어렵습니다.

---

## 3. 정밀도(Precision)

- **정의**: Positive로 예측한 것 중에서 실제로 Positive인 비율.
- **공식**:  
  $$
  \text{정밀도} = \frac{TP}{TP + FP}
  $$
- **해석**: 예측이 Positive일 때, 실제로 맞을 확률입니다.
- **중요 상황**: 스팸메일 분류 등, 오탐(FP)이 비용이 큰 경우.

---

## 4. 재현율(Recall, 민감도)

- **정의**: 실제 Positive 중에서 모델이 Positive로 잘 맞춘 비율.
- **공식**:  
  $$
  \text{재현율} = \frac{TP}{TP + FN}
  $$
- **해석**: 실제 Positive를 얼마나 놓치지 않고 잡았는지 나타냅니다.
- **중요 상황**: 암 진단, 결함 검출 등, 미탐(FN)이 치명적인 경우.

---

## 5. F1 Score

- **정의**: 정밀도와 재현율의 조화 평균.
- **공식**:  
  $$
  \text{F1 score} = 2 \times \frac{\text{정밀도} \times \text{재현율}}{\text{정밀도} + \text{재현율}}
  $$
- **해석**: 정밀도와 재현율이 모두 중요할 때 사용하는 지표입니다. 한쪽이 낮으면 F1도 낮아집니다.
- **활용**: 불균형 데이터에서 모델 평가에 적합.

---

## 6. ROC 곡선과 AUC

- **ROC 곡선(Receiver Operating Characteristic Curve)**
    - **정의**: 다양한 임계값에서 FPR(위양성률)과 TPR(재현율)의 관계를 그래프로 표현.
    - **X축**: FPR (False Positive Rate) = FP / (FP + TN)
    - **Y축**: TPR (True Positive Rate, 재현율) = TP / (TP + FN)
    - **해석**: 곡선이 왼쪽 위에 가까울수록 좋은 모델입니다.
- **AUC (Area Under Curve)**
    - **정의**: ROC 곡선 아래 면적.
    - **범위**: 0.5(랜덤) ~ 1(완벽)
    - **해석**: 1에 가까울수록 분류 성능이 우수합니다.
    <img src="https://t1.daumcdn.net/cfile/tistory/262E8E3F544837AD27">

---

## 7. 정리 표

| 지표         | 공식                                  | 의미 및 활용 예시                   |
|--------------|--------------------------------------|-------------------------------------|
| 정확도       | (TP+TN)/(TP+TN+FP+FN)                | 전체 예측 중 맞춘 비율              |
| 정밀도       | TP/(TP+FP)                           | Positive 예측의 신뢰도(오탐 최소화) |
| 재현율       | TP/(TP+FN)                           | 실제 Positive를 놓치지 않는 비율    |
| F1 Score     | 2×(정밀도×재현율)/(정밀도+재현율)    | 정밀도·재현율의 균형                |
| ROC AUC      | ROC 곡선 아래 면적                    | 임계값 변화에 따른 전체 성능         |

---

## 8. 실제 적용 시 주의점

- 데이터의 특성과 목적에 따라 적합한 지표를 선택해야 합니다.
- 한 가지 지표만으로 모델을 평가하면 왜곡될 수 있으므로, 여러 지표를 함께 보는 것이 중요합니다.
