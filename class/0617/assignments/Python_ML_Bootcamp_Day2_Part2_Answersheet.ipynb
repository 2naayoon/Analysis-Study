{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔑 Part 2 연습문제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 연습문제 정답"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNFa-upj6We3"
      },
      "outputs": [],
      "source": [
        "# 연습문제 1 정답\n",
        "imputer_median = SimpleImputer(strategy='median')\n",
        "df_imputed_median = imputer_median.fit_transform(df_numeric)\n",
        "df_imputed_median = pd.DataFrame(df_imputed_median, columns=df_numeric.columns)\n",
        "# 중앙값으로 채워진 후 결측치가 없는지 확인\n",
        "print(\"중앙값 처리 후 결측치 개수:\", df_imputed_median['TotalCharges'].isnull().sum()) # 출력: 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 연습문제 2 정답\n",
        "dependents_series = df['Dependents']\n",
        "le_dependents = LabelEncoder()\n",
        "dependents_encoded = le_dependents.fit_transform(dependents_series)\n",
        "print(\"원본 데이터:\", dependents_series.unique()) # ['No' 'Yes']\n",
        "print(\"인코딩된 데이터:\", np.unique(dependents_encoded)) # [0 1]\n",
        "print(\"인코딩 클래스 확인:\", le_dependents.classes_) # ['No' 'Yes']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 연습문제 3 정답\n",
        "payment_df = df[['PaymentMethod']]\n",
        "ohe_payment = OneHotEncoder(sparse_output=False)\n",
        "payment_onehot = ohe_payment.fit_transform(payment_df.fillna('Unknown'))\n",
        "print(\"생성된 더미 변수 개수(shape):\", payment_onehot.shape) # (7043, 4)\n",
        "print(\"생성된 컬럼명:\", ohe_payment.get_feature_names_out())\n",
        "# ['PaymentMethod_Bank transfer (automatic)' 'PaymentMethod_Credit card (automatic)' 'PaymentMethod_Electronic check' 'PaymentMethod_Mailed check']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 연습문제 4 정답\n",
        "df_subset = df_imputed[['tenure', 'TotalCharges']]\n",
        "scaler_subset = StandardScaler()\n",
        "df_scaled_subset = scaler_subset.fit_transform(df_subset)\n",
        "print(df_scaled_subset[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 연습문제 5 정답\n",
        "print(pd.Series(y_train_resampled).value_counts(normalize=True))\n",
        "# 0    0.5\n",
        "# 1    0.5\n",
        "# Name: proportion, dtype: float64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 연습문제 6 정답\n",
        "from lib.preperate import ImbalancedDataAnalyzer\n",
        "from lib.visualize import TSNEVisualizer\n",
        "from sklearn.utils import resample\n",
        "\n",
        "analyzer = ImbalancedDataAnalyzer(X_train, y_train)\n",
        "\n",
        "X_adasyn, y_adasyn = analyzer.adasyn()\n",
        "print(f\"ADASYN 샘플링 후 데이터 크기: {X_adasyn.shape}\")\n",
        "print(f\"ADASYN 클래스 분포:\\n{pd.Series(y_adasyn).value_counts()}\")\n",
        "\n",
        "X_smote_tomek, y_smote_tomek = analyzer.smote_tomek()\n",
        "print(f\"\\nSMOTE+Tomek 샘플링 후 데이터 크기: {X_smote_tomek.shape}\")\n",
        "print(f\"SMOTE+Tomek 클래스 분포:\\n{pd.Series(y_smote_tomek).value_counts()}\")\n",
        "\n",
        "X_smote_enn, y_smote_enn = analyzer.smote_enn()\n",
        "print(f\"\\nSMOTE+ENN 샘플링 후 데이터 크기: {X_smote_enn.shape}\")\n",
        "print(f\"SMOTE+ENN 클래스 분포:\\n{pd.Series(y_smote_enn).value_counts()}\")\n",
        "\n",
        "df_adasyn = pd.DataFrame(X_adasyn, columns=X_train.columns)\n",
        "df_adasyn['target'] = y_adasyn\n",
        "X_adasyn_sample, y_adasyn_sample = resample(df_adasyn.drop('target', axis=1), \n",
        "                                           df_adasyn['target'], \n",
        "                                           n_samples=3000, \n",
        "                                           random_state=42)\n",
        "\n",
        "df_smote_tomek = pd.DataFrame(X_smote_tomek, columns=X_train.columns)\n",
        "df_smote_tomek['target'] = y_smote_tomek\n",
        "X_smote_tomek_sample, y_smote_tomek_sample = resample(df_smote_tomek.drop('target', axis=1), \n",
        "                                                     df_smote_tomek['target'], \n",
        "                                                     n_samples=3000, \n",
        "                                                     random_state=42)\n",
        "\n",
        "df_smote_enn = pd.DataFrame(X_smote_enn, columns=X_train.columns)\n",
        "df_smote_enn['target'] = y_smote_enn\n",
        "X_smote_enn_sample, y_smote_enn_sample = resample(df_smote_enn.drop('target', axis=1), \n",
        "                                                 df_smote_enn['target'], \n",
        "                                                 n_samples=3000, \n",
        "                                                 random_state=42)\n",
        "\n",
        "print(f\"\\n3000개 샘플링 후:\")\n",
        "print(f\"ADASYN 클래스 분포: {pd.Series(y_adasyn_sample).value_counts()}\")\n",
        "print(f\"SMOTE+Tomek 클래스 분포: {pd.Series(y_smote_tomek_sample).value_counts()}\")\n",
        "print(f\"SMOTE+ENN 클래스 분포: {pd.Series(y_smote_enn_sample).value_counts()}\")\n",
        "\n",
        "TSNEVisualizer.visualize(X_adasyn_sample, y_adasyn_sample, 'ADASYN t-SNE 시각화')\n",
        "TSNEVisualizer.visualize(X_smote_tomek_sample, y_smote_tomek_sample, 'SMOTE+Tomek t-SNE 시각화')\n",
        "TSNEVisualizer.visualize(X_smote_enn_sample, y_smote_enn_sample, 'SMOTE+ENN t-SNE 시각화')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 연습문제 7 정답\n",
        "numeric_transformer_minmax = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "preprocessor_minmax = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer_minmax, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "model_pipeline_minmax = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor_minmax),\n",
        "    ('classifier', LogisticRegression(solver='liblinear'))\n",
        "])\n",
        "model_pipeline_minmax.fit(X_train, y_train)\n",
        "accuracy_minmax = model_pipeline_minmax.score(X_test, y_test)\n",
        "print(f\"MinMaxScaler 파이프라인 모델의 정확도: {accuracy_minmax:.4f}\") # 0.8204"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 연습문제 8 정답\n",
        "\n",
        "# 특성(X)과 타겟(y) 분리\n",
        "X = df_heart.drop('DEATH_EVENT', axis=1)\n",
        "y = df_heart['DEATH_EVENT']\n",
        "\n",
        "# 훈련/테스트 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "# [문제 1] 수치형 특성과 범주형(이진) 특성의 컬럼명을 리스트로 정의하세요.\n",
        "numeric_features = ['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'time']\n",
        "categorical_features = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']\n",
        "\n",
        "# [문제 2] ColumnTransformer를 사용하여 전처리기를 만드세요.\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(), categorical_features)\n",
        "    ])\n",
        "\n",
        "# [문제 3] Pipeline을 사용하여 전처리기와 RandomForestClassifier 모델을 연결하세요.\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# [문제 4] 생성한 파이프라인을 훈련 데이터로 학습시키세요.\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# [문제 5] 학습된 파이프라인으로 테스트 데이터의 예측을 수행하고 정확도를 계산하여 출력하세요.\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"심부전 예측 모델 파이프라인의 정확도: {accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
